# Fully Convolutional Dense Networks for High-Quality Monocular Depth Estimation


 *Estimating depth from a single RGB image is an ill-posed problem that requires both global and local information. This problem plays an important role in various applications including autonomous driving and scene understanding. We tackle this problem by leveraging transfer learning and by using an encoder-decoder architecture that is trained end-to-end. A combination of three suitable losses has been used for optimization. We demonstrate through careful ablation studies that our network produces comparable results on the NYU Depth v2 dataset and captures the object boundaries faithfully.*


# Results


## Qualitative

(images comparison)

## Quantitative


(metrics table)

# Instructions

<details>
<summary>
Data:
</summary>
</details>

<details>
<summary>
Training:
</summary>
</details>

<details>
<summary>
Inference:
</summary>
</details>

# Pre-trained models

Model
